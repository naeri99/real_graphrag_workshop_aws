"""
OpenSearch ì—”í‹°í‹° ê²€ìƒ‰ ìœ í‹¸ë¦¬í‹°
"""
from typing import Dict, List, Tuple
from opensearch.opensearch_con import get_opensearch_client


def search_entity_by_synonym(
    entity_name: str, 
    entity_type: str, 
    opensearch_client=None, 
    index_name: str = "entities"
) -> Tuple[str, bool, str]:
    """
    OpenSearchì—ì„œ ë™ì˜ì–´ë¥¼ í†µí•´ ì—”í‹°í‹°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        entity_name: ê²€ìƒ‰í•  ì—”í‹°í‹° ì´ë¦„
        entity_type: ì—”í‹°í‹° íƒ€ì… (ACTOR, MOVIE_CHARACTER, etc.)
        opensearch_client: OpenSearch í´ë¼ì´ì–¸íŠ¸ (Noneì´ë©´ ìë™ ìƒì„±)
        index_name: ê²€ìƒ‰í•  ì¸ë±ìŠ¤ ì´ë¦„
        
    Returns:
        Tuple[str, bool, str]: (ì •í™•í•œ ì—”í‹°í‹° ì´ë¦„, ë§¤ì¹­ ì„±ê³µ ì—¬ë¶€, ë§¤ì¹­ íƒ€ì…)
        ë§¤ì¹­ íƒ€ì…: 'synonym_exact', 'synonym_partial', 'name_exact', 'not_found'
    """
    if opensearch_client is None:
        opensearch_client = get_opensearch_client()
    
    entity_name = entity_name.strip() if entity_name else ""
    entity_type = entity_type.strip() if entity_type else ""
    
    if not entity_name or not entity_type:
        return entity_name, False, 'not_found'
    
    try:
        # 1. í•´ë‹¹ íƒ€ì…ì˜ ëª¨ë“  ì—”í‹°í‹°ì—ì„œ ë™ì˜ì–´ ê²€ìƒ‰
        search_body = {
            "query": {
                "term": {
                    "entity.entity_type": entity_type
                }
            },
            "size": 100,
            "_source": ["entity.name", "entity.synonym", "entity.entity_type"]
        }
        
        response = opensearch_client.search(index=index_name, body=search_body)
        hits = response.get('hits', {}).get('hits', [])
        
        # ì •í™•í•œ ë™ì˜ì–´ ë§¤ì¹­ ì°¾ê¸°
        for hit in hits:
            entity = hit['_source'].get('entity', {})
            entity_real_name = entity.get('name', '').strip()
            synonyms = entity.get('synonym', '')
            
            if not synonyms:
                continue
            
            if isinstance(synonyms, str):
                synonym_list = [s.strip() for s in synonyms.split(',') if s.strip()]
            else:
                synonym_list = synonyms if isinstance(synonyms, list) else []
            
            # ì •í™•í•œ ë§¤ì¹­
            if entity_name in synonym_list:
                return entity_real_name, True, 'synonym_exact'
            
            # ë¶€ë¶„ ë§¤ì¹­
            if any(entity_name in syn for syn in synonym_list):
                return entity_real_name, True, 'synonym_partial'
        
        # 2. ì •í™•í•œ ì´ë¦„ ë§¤ì¹­ ì‹œë„
        exact_search_body = {
            "query": {
                "bool": {
                    "must": [
                        {
                            "bool": {
                                "should": [
                                    {"term": {"entity.name.keyword": {"value": entity_name, "boost": 3.0}}},
                                    {"match": {"entity.name": {"query": entity_name, "operator": "and", "boost": 2.0}}}
                                ]
                            }
                        },
                        {"term": {"entity.entity_type": entity_type}}
                    ]
                }
            },
            "size": 1,
            "_source": ["entity.name"]
        }
        
        response = opensearch_client.search(index=index_name, body=exact_search_body)
        hits = response.get('hits', {}).get('hits', [])
        
        if hits:
            exact_name = hits[0]['_source'].get('entity', {}).get('name', entity_name).strip()
            return exact_name, True, 'name_exact'
        
        # ë§¤ì¹­ ì‹¤íŒ¨ - ì›ë³¸ ì´ë¦„ ë°˜í™˜
        return entity_name, False, 'not_found'
        
    except Exception as e:
        print(f"   âŒ OpenSearch ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return entity_name, False, 'not_found'


def resolve_entities_with_cache(
    entities: List[Dict], 
    opensearch_client=None, 
    index_name: str = "entities"
) -> Tuple[List[Dict], Dict[str, str], Dict]:
    """
    ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¥¼ OpenSearchë¥¼ í†µí•´ í•´ê²°í•˜ê³  ìºì‹œì™€ ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        entities: ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
        opensearch_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ê²€ìƒ‰í•  ì¸ë±ìŠ¤ ì´ë¦„
        
    Returns:
        Tuple[List[Dict], Dict[str, str], Dict]: 
            - í•´ê²°ëœ ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
            - ì´ë¦„ ë§¤í•‘ ìºì‹œ
            - ë©”íŠ¸ë¦­ {matched_existing, new_entities, synonym_exact, synonym_partial, name_exact}
    """
    if opensearch_client is None:
        opensearch_client = get_opensearch_client()
    
    if not entities:
        return [], {}, {'matched_existing': 0, 'new_entities': 0, 'synonym_exact': 0, 'synonym_partial': 0, 'name_exact': 0}
    
    resolved_entities = []
    name_cache = {}  # {(original_name, entity_type): resolved_name}
    
    metrics = {
        'matched_existing': 0,  # ê¸°ì¡´ ì—”í‹°í‹°ì— ë§¤í•‘ëœ ìˆ˜
        'new_entities': 0,      # ìƒˆë¡œ ìƒì„±ë  ì—”í‹°í‹° ìˆ˜
        'synonym_exact': 0,     # ë™ì˜ì–´ ì •í™• ë§¤ì¹­
        'synonym_partial': 0,   # ë™ì˜ì–´ ë¶€ë¶„ ë§¤ì¹­
        'name_exact': 0,        # ì´ë¦„ ì •í™• ë§¤ì¹­
        'mappings': []          # ë§¤í•‘ ìƒì„¸ ì •ë³´
    }
    
    for entity in entities:
        original_name = entity.get('entity_name', '').strip()
        entity_type = entity.get('entity_type', '').strip()
        
        if not original_name or not entity_type:
            resolved_entities.append(entity)
            continue
        
        cache_key = (original_name, entity_type)
        
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        if cache_key in name_cache:
            resolved_name = name_cache[cache_key]
            found = resolved_name != original_name
            match_type = 'cached'
        else:
            # OpenSearchì—ì„œ ê²€ìƒ‰
            resolved_name, found, match_type = search_entity_by_synonym(
                original_name, entity_type, opensearch_client, index_name
            )
            name_cache[cache_key] = resolved_name
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        if found:
            metrics['matched_existing'] += 1
            if match_type == 'synonym_exact':
                metrics['synonym_exact'] += 1
            elif match_type == 'synonym_partial':
                metrics['synonym_partial'] += 1
            elif match_type == 'name_exact':
                metrics['name_exact'] += 1
            
            if resolved_name != original_name:
                metrics['mappings'].append({
                    'original': original_name,
                    'resolved': resolved_name,
                    'type': entity_type,
                    'match_type': match_type
                })
                print(f"   âœ… '{original_name}' â†’ '{resolved_name}' ({entity_type}) [{match_type}]")
        else:
            metrics['new_entities'] += 1
            print(f"   ğŸ†• '{original_name}' ({entity_type}) [NEW]")
        
        # ì—”í‹°í‹° ì—…ë°ì´íŠ¸
        updated_entity = entity.copy()
        updated_entity['entity_name'] = resolved_name
        updated_entity['_is_new'] = not found  # ìƒˆ ì—”í‹°í‹° ì—¬ë¶€ í‘œì‹œ
        updated_entity['_match_type'] = match_type
        resolved_entities.append(updated_entity)
    
    return resolved_entities, name_cache, metrics


def resolve_relationships_with_cache(
    relationships: List[Dict], 
    name_cache: Dict[str, str],
    opensearch_client=None, 
    index_name: str = "entities"
) -> Tuple[List[Dict], Dict]:
    """
    ê´€ê³„ ë¦¬ìŠ¤íŠ¸ì˜ ì—”í‹°í‹° ì´ë¦„ì„ ìºì‹œë¥¼ í™œìš©í•˜ì—¬ í•´ê²°í•©ë‹ˆë‹¤.
    
    Args:
        relationships: ê´€ê³„ ë¦¬ìŠ¤íŠ¸
        name_cache: ì—”í‹°í‹° ì´ë¦„ ë§¤í•‘ ìºì‹œ {(original_name, type): resolved_name}
        opensearch_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ê²€ìƒ‰í•  ì¸ë±ìŠ¤ ì´ë¦„
        
    Returns:
        Tuple[List[Dict], Dict]: (í•´ê²°ëœ ê´€ê³„ ë¦¬ìŠ¤íŠ¸, ë©”íŠ¸ë¦­)
    """
    if opensearch_client is None:
        opensearch_client = get_opensearch_client()
    
    if not relationships:
        return [], {'source_matched': 0, 'source_new': 0, 'target_matched': 0, 'target_new': 0}
    
    resolved_relationships = []
    metrics = {
        'source_matched': 0,
        'source_new': 0,
        'target_matched': 0,
        'target_new': 0
    }
    
    for rel in relationships:
        updated_rel = rel.copy()
        
        # Source ì—”í‹°í‹° í•´ê²°
        source_name = rel.get('source_entity', '').strip()
        source_type = rel.get('source_type', '').strip()
        
        if source_name and source_type:
            cache_key = (source_name, source_type)
            if cache_key in name_cache:
                updated_rel['source_entity'] = name_cache[cache_key]
                metrics['source_matched'] += 1
            else:
                resolved_name, found, _ = search_entity_by_synonym(
                    source_name, source_type, opensearch_client, index_name
                )
                updated_rel['source_entity'] = resolved_name
                name_cache[cache_key] = resolved_name
                if found:
                    metrics['source_matched'] += 1
                else:
                    metrics['source_new'] += 1
        
        # Target ì—”í‹°í‹° í•´ê²°
        target_name = rel.get('target_entity', '').strip()
        target_type = rel.get('target_type', '').strip()
        
        if target_name and target_type:
            cache_key = (target_name, target_type)
            if cache_key in name_cache:
                updated_rel['target_entity'] = name_cache[cache_key]
                metrics['target_matched'] += 1
            else:
                resolved_name, found, _ = search_entity_by_synonym(
                    target_name, target_type, opensearch_client, index_name
                )
                updated_rel['target_entity'] = resolved_name
                name_cache[cache_key] = resolved_name
                if found:
                    metrics['target_matched'] += 1
                else:
                    metrics['target_new'] += 1
        
        resolved_relationships.append(updated_rel)
    
    return resolved_relationships, metrics
