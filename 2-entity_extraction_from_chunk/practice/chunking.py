"""
Entity Extraction from Chunk Pipeline
Flow:
1. Extract entities from chunk (LLM)
2. Resolve entity names via OpenSearch (synonym matching)
3. Save entities to Neptune
4. Resolve relationship names using cache
5. Save relationships to Neptune
"""
from langchain_text_splitters import RecursiveCharacterTextSplitter
from utils.parse_utils import parse_extraction_output
from utils.helper import (
    get_context_from_review_file, 
    get_all_review_files,
    generate_chunk_hash,
    generate_chunk_id
)
from opensearch.opensearch_con import get_opensearch_client
from opensearch.opensearch_search import resolve_entities, resolve_relationships, delete_chunk_index_opensearch
from neptune.cyper_queries import (
    import_nodes_with_dynamic_label,
    import_relationships_with_dynamic_label,
    delete_all_nodes_and_relationships,
    get_database_stats
)
import time
import json
import os
from pathlib import Path


def save_chunk_to_json(chunk_data: dict, output_dir: str = "./step/chunkings") -> str:
    """
    Chunk ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        chunk_data: ì €ì¥í•  chunk ë°ì´í„° (chunk_hash, chunk_id, user_query í¬í•¨)
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # íŒŒì¼ëª…: chunk_id ì‚¬ìš©
    filename = f"{chunk_data['chunk_id']}.json"
    filepath = os.path.join(output_dir, filename)
    
    # JSON ì €ì¥
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(chunk_data, f, ensure_ascii=False, indent=2)
    
    print(f"   ğŸ’¾ Saved: {filepath}")
    return filepath


def save_all_chunks_to_json(chunks_list: list, output_dir: str = "./step/chunkings") -> str:
    """
    ëª¨ë“  chunk ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        chunks_list: chunk ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    os.makedirs(output_dir, exist_ok=True)
    
    filepath = os.path.join(output_dir, "all_chunks.json")
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(chunks_list, f, ensure_ascii=False, indent=2)
    
    print(f"   ğŸ’¾ Saved all chunks: {filepath}")
    return filepath

def clear_output_directory(output_dir: str = "./step/chunkings"):
    """
    ì¶œë ¥ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    dir_path = Path(output_dir)
    if dir_path.exists():
        for file in dir_path.glob("*.json"):
            file.unlink()
        print(f"ğŸ—‘ï¸ Cleared: {output_dir}")


def get_chunk(reviews_dir):
    if reviews_dir:
        from pathlib import Path
        review_files = list(Path(reviews_dir).rglob("*.json"))
    else:
        review_files = get_all_review_files()
    return review_files


