"""
Entity Extraction from Chunk Pipeline
Flow:
1. movie_cast JSONì—ì„œ review ê²½ë¡œ ë¡œë“œ
2. review/ ë””ë ‰í† ë¦¬ì˜ refined_transcript ê¸°ì¤€ìœ¼ë¡œ chunking
3. chunk ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
"""
from langchain_text_splitters import RecursiveCharacterTextSplitter
from utils.helper import (
    generate_chunk_hash,
    generate_chunk_id
)
import glob
import json
import os
from pathlib import Path

# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ê¸°ì¤€ ë””ë ‰í† ë¦¬
SCRIPT_DIR = Path(__file__).parent.resolve()
DEFAULT_OUTPUT_DIR = SCRIPT_DIR / "step" / "chunkings"

# movie_cast ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’)
DEFAULT_CAST_DIR = os.path.normpath(os.path.join(
    os.path.dirname(os.path.abspath(__file__)),
    os.pardir, os.pardir, "data", "raw_csv", "movie_cast"
))


def save_chunk_to_json(chunk_data: dict, output_dir: str = None) -> str:
    """
    Chunk ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        chunk_data: ì €ì¥í•  chunk ë°ì´í„° (chunk_hash, chunk_id, user_query í¬í•¨)
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    # ë””ë ‰í† ë¦¬ ìƒì„± (ê¸°ë³¸ê°’: ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€)
    if output_dir is None:
        output_dir = DEFAULT_OUTPUT_DIR
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # íŒŒì¼ëª…: chunk_id ì‚¬ìš©
    filename = f"{chunk_data['chunk_id']}.json"
    filepath = os.path.join(output_dir, filename)
    
    # JSON ì €ì¥
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(chunk_data, f, ensure_ascii=False, indent=2)
    
    print(f"   ğŸ’¾ Saved: {filepath}")
    return filepath


def save_all_chunks_to_json(chunks_list: list, output_dir: str = None) -> str:
    """
    ëª¨ë“  chunk ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        chunks_list: chunk ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if output_dir is None:
        output_dir = DEFAULT_OUTPUT_DIR
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    filepath = output_dir / "all_chunks.json"
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(chunks_list, f, ensure_ascii=False, indent=2)
    
    print(f"   ğŸ’¾ Saved all chunks: {filepath}")
    return filepath

def clear_output_directory(output_dir: str = None):
    """
    ì¶œë ¥ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    if output_dir is None:
        output_dir = DEFAULT_OUTPUT_DIR
    dir_path = Path(output_dir)
    if dir_path.exists():
        for file in dir_path.glob("*.json"):
            file.unlink()
        print(f"ğŸ—‘ï¸ Cleared: {output_dir}")


def get_chunk(cast_dir):
    """movie_cast ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ, review ê²½ë¡œì˜ refined_transcript ë°˜í™˜
    
    Returns:
        list of (review_path, refined_transcript, movie_title, channel_name)
    """
    cast_files = sorted(glob.glob(os.path.join(cast_dir, "*.json")))
    print(f"ğŸ“‚ ì´ {len(cast_files)}ê°œ ì˜í™” ë°œê²¬")
    
    review_items = []
    for cast_file in cast_files:
        with open(cast_file, "r", encoding="utf-8") as f:
            cast_data = json.load(f)
        
        movie_title = cast_data["movie_title"]
        review_paths = cast_data.get("review", [])
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ (movie_cast ê¸°ì¤€ ../../..)
        project_root = os.path.normpath(os.path.join(os.path.dirname(os.path.abspath(__file__)), os.pardir, os.pardir))
        
        for rpath in review_paths:
            # ìƒëŒ€ê²½ë¡œ(./data/review/...) â†’ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜
            if rpath.startswith("./"):
                rpath = os.path.join(project_root, rpath[2:])
            try:
                with open(rpath, "r", encoding="utf-8") as f:
                    data = json.load(f)
                rt = data.get("refined_transcript", "")
                if not rt:
                    print(f"   â­ï¸  refined_transcript ì—†ìŒ, ìŠ¤í‚µ: {os.path.basename(rpath)}")
                    continue
                channel_name = data.get("channel_name", "unknown")
                # íŒŒì¼ëª…ì— ì‚¬ìš© ë¶ˆê°€í•œ ë¬¸ì ì œê±°
                channel_name = channel_name.replace("/", "_").replace("\\", "_")
                review_items.append((rpath, rt, movie_title, channel_name))
            except Exception as e:
                print(f"   â­ï¸  íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ìŠ¤í‚µ: {os.path.basename(rpath)} ({e})")
    
    print(f"ğŸ“„ ì´ {len(review_items)}ê°œ ë¦¬ë·° ë¡œë“œ ì™„ë£Œ")
    return review_items


def run_chunking(
    cast_dir: str = None,
    chunk_size: int = 1500,
    chunk_overlap: int = 100,
    output_dir: str = None
):
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • (ê¸°ë³¸ê°’: ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€)
    if output_dir is None:
        output_dir = DEFAULT_OUTPUT_DIR
    output_dir = Path(output_dir)
    
    # cast ë””ë ‰í† ë¦¬ ì„¤ì •
    if cast_dir is None:
        cast_dir = DEFAULT_CAST_DIR
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
    clear_output_directory(output_dir)
    
    # movie_castì—ì„œ review ì •ë³´ ë¡œë“œ
    review_items = get_chunk(cast_dir)
    
    # í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    
    for i, (review_path, transcript, movie_id, reviewer) in enumerate(review_items, 1):
        review_filename = os.path.basename(review_path)
        print(f"\n{'='*60}")
        print(f"ğŸ“„ [{i}/{len(review_items)}] {review_filename}")
        print('='*60)
        print(f"   ğŸ¬ Movie: {movie_id}, Reviewer: {reviewer}")
        
        # ì²­í‚¹
        chunks = text_splitter.split_text(transcript)
        print(f"   ğŸ“ Chunks: {len(chunks)}")
        
        for j, chunk in enumerate(chunks, 1):
            print(f"\n   --- Chunk {j}/{len(chunks)} ---")
            print(f"   {chunk[:800]}... ìƒëµ ...")
            chunk_hash = generate_chunk_hash(chunk)
            chunk_id = generate_chunk_id(reviewer, chunk_hash)

            # Step 1: chunk ë°ì´í„° êµ¬ì„± ë° ì €ì¥
            save_chunk = {
                "chunk_hash": chunk_hash,
                "chunk_id": chunk_id,
                "user_query": chunk,
                "movie_id": movie_id,
                "reviewer": reviewer,
                "chunk_index": j,
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            save_chunk_to_json(save_chunk, output_dir)


if __name__ == "__main__":
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    run_chunking(
        cast_dir=DEFAULT_CAST_DIR,
        chunk_size=1500,
        chunk_overlap=100
    )
    print(f"ğŸ“ Output directory: {DEFAULT_OUTPUT_DIR}")
