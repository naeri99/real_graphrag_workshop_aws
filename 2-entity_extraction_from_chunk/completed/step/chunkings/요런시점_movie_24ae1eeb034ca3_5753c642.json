{
  "chunk_hash": "24ae1eeb034ca3",
  "chunk_id": "요런시점_movie_24ae1eeb034ca3_5753c642",
  "user_query": "자존심이 상해서였는지 구체적으로 얘기를 안 하고 이 정도로 끝나고 있습니다 속 시원하게 의문이 뻥 뚫리는 그런 설명은 아닌 것 같은데요 하지만 HAL의\n이 오작동 에피소드는 인공지능 과학자들이 지적하는 아주 중요한 문제를\n환기하고 있습니다 그것은 바로 인공지능에게 어떻게 목적을\n부여할 것인가 하는 문제이죠 인공지능 연구도\n하고 있는 것으로 알려진 유명 물리학자\n맥스 테그마크는 이렇게 말하고 있습니다 초지능 AI는 자기 목적을\n달성하는 방법을 고안하는 데 인간보다 훨씬\n뛰어날 것입니다 우리는 이미 알파고가 인간이 생각지도 못한\n기발한 수를 두어서 그래도 이세돌을\n이기는 장면을 보았습니다 문제는 지능이 높고\n다양한 일을 할 수 있는 A.G.I.일수록\n그가 추구하는 목적을 인간의 가치에 맞게\n정렬시키는 일이 훨씬 더 어려워진다는 것입니다 인간이 A.I.에게\n어떤 목적을 부여하면 A.I.는 그 목적을\n달성하는 데 수반되는 온갖 천재적인 방법들을\n개발해 낼 것입니다 또 그 방법들을\n실행하기 위해서 다시 다양한 하위 목표들을 혼자서 생성해 내게 됩니다 예를 들어 유명한 SF작가인\n아이작 아시모프가 그의 대표작인\n\"아이 로봇\"에서 말했던 \"로봇 3원칙\" 중에서 로봇은 로봇 자신을\n지켜야 한다는 원칙은 실제 A.I.에는\n필요가 없다고 합니다 왜냐하면 A.I.에게\n어떤 목적이 주어진다면 그는 그 목적을 달성하기 위해서 자신을 보호하겠다는 하위 목표를 자동적으로\n생성해 내기 때문입니다 이렇게 원래 목적을\n달성하는 데 유용한 하위목표를 \"도구적 목표\"라고 하는데요 그런데 초지능 A.G.I.는 인간이 미처 생각지도 못하는 다양하고 기발한\n수많은 도구적 목표들을 혼자서 만들어낼 수 있습니다 문제는 그렇게 A.I.가\n자체 설정한 도구적 목표 중에서 인간에게 해로운 목표가\n하나도 없다고는 누구도 보장할 수가\n없다는 것입니다 물론 그런 경우를\n미연에 방지하기 위해서 인공지능 과학자들이\n열심히 관리를 해야 되겠지만 A.I. 생각의 속도가\n인간보다 훨씬 더 빠르기 때문에 제때 제때 막아내기가 정말 어려울 거라는 거죠 심지어 초지능 A.I.는\n자신의 목적을 스스로 재정렬할\n가능성도 있다고 합니다 예를 들어\n사람을 죽이지 말라는 원칙이 가장 중요한 최고의 목적을\n효율적으로 추구하는 데 방해가 되더라 그럼 자신을 구속하는\n불살원칙을 없애도록 꼼수를 개발할 수도\n있다는 것입니다 초지능 A.I.에게 인간은 다섯 살짜리\n아이만도 못하기 때문에 어르고 속여서\n조종할 수 있는 방법은 얼마든지 있다는 것입니다 이렇게 A.I.의 목적을 인간의 가치에 맞게\n정렬시키는 문제를 가치정렬의 문제라고 하는데요 사이버네틱스의 창시자인\n노버트 위너는 일찍이 이를 괴테의\n\"마법사의 제자\" 이야기에 비유한 적이 있습니다 이 미키마우스가 그랬던 것처럼 우리가 초지능 A.I.에게 인간에게 이로운 목적의식을\n주입한다고 하더라도 그것이 실제 인간에게\n이로운 결과를 가져올지는 전혀 확신할 수가\n없다는 것입니다 인간은 A.I.가 왜 그러는지 이유를 전혀\n파악도 못한 상태에서 뜻밖의 치명적인 뒤통수를",
  "movie_id": "2001 스페이스 오디세이",
  "reviewer": "요런시점_movie",
  "chunk_index": 3
}