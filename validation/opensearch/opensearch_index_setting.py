# from utils.bedrock_embedding import create_embeddings
import json


def check_index_exists(opensearch_client, index_name):
    """ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    try:
        return opensearch_client.indices.exists(index=index_name)
    except Exception as e:
        print(f"Error checking index existence: {e}")
        return False


def delete_index(opensearch_client, index_name):
    """OpenSearch ì¸ë±ìŠ¤ ì‚­ì œ"""
    try:
        if not check_index_exists(opensearch_client, index_name):
            print(f"Index '{index_name}' does not exist, skipping deletion")
            return True
            
        response = opensearch_client.indices.delete(index=index_name)
        print(f"âœ… Index '{index_name}' deleted successfully")
        return response
    except Exception as e:
        print(f"âŒ Error deleting index '{index_name}': {e}")
        return None


def define_chunk_index(opensearch_client, index_name):
    """ì²­í¬ìš© OpenSearch ì¸ë±ìŠ¤ ìƒì„±"""
    
    # ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if check_index_exists(opensearch_client, index_name):
        print(f"âš ï¸ Index '{index_name}' already exists")
        
        # ê¸°ì¡´ ë§¤í•‘ í™•ì¸
        mapping_valid = validate_chunk_mapping(opensearch_client, index_name)
        if mapping_valid:
            print(f"âœ… Index '{index_name}' has valid mapping")
            return {"acknowledged": True, "index": index_name, "status": "already_exists"}
        else:
            print(f"âŒ Index '{index_name}' has invalid mapping, consider recreating")
            return None
    
    index_settings = {
        "settings": {
            "index": {
                "knn": True,
                "knn.algo_param.ef_search": 100,
                "number_of_shards": 3,
                "number_of_replicas": 2,
                "analysis": {
                    "analyzer": {
                        "nori_analyzer": {
                            "tokenizer": "nori_tokenizer",
                            "filter": ["nori_stop", "lowercase"]
                        }
                    },
                    "filter": {
                        "nori_stop": {
                            "type": "nori_part_of_speech",
                            "stoptags": ["J", "JKS", "JKB", "JKO", "JKG", "JKC", "JKV", "JKQ", "JX", "JC"]
                        }
                    }
                }
            }
        },
        "mappings": {
            "properties": {
                "chunk": {
                    "properties": {
                        "chunk_id": {
                            "type": "text",
                            "analyzer": "nori_analyzer"
                        },
                        "chunk_text": {
                            "type": "text",
                            "analyzer": "nori_analyzer"
                        },
                        "source_id": {
                            "type": "keyword"
                        },
                        "summary": {
                            "type": "text",
                            "analyzer": "nori_analyzer"
                        },
                        "summary_vec": {
                            "type": "knn_vector",
                            "dimension": 1024,
                            "method": {
                                "name": "hnsw",
                                "space_type": "l2",
                                "engine": "faiss",
                                "parameters": {
                                    "ef_construction": 128,
                                    "m": 16
                                }
                            }
                        },
                        "neptune_id": {
                            "type": "keyword"
                        }
                    }
                }
            }
        }
    }
    
    try:
        response = opensearch_client.indices.create(
            index=index_name,
            body=index_settings
        )
        print(f"âœ… Chunk index '{index_name}' created successfully")
        
        # ìƒì„±ëœ ë§¤í•‘ ê²€ì¦
        if validate_chunk_mapping(opensearch_client, index_name):
            print(f"âœ… Chunk index mapping validation passed")
        else:
            print(f"âš ï¸ Chunk index mapping validation failed")
            
        return response
    except Exception as e:
        print(f"âŒ Error creating chunk index '{index_name}': {e}")
        return None


def define_entity_index(opensearch_client, index_name):
    """ì—”í‹°í‹°ìš© OpenSearch ì¸ë±ìŠ¤ ìƒì„±"""
    
    # ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if check_index_exists(opensearch_client, index_name):
        print(f"âš ï¸ Index '{index_name}' already exists")
        
        # ê¸°ì¡´ ë§¤í•‘ í™•ì¸
        mapping_valid = validate_entity_mapping(opensearch_client, index_name)
        if mapping_valid:
            print(f"âœ… Index '{index_name}' has valid mapping")
            return {"acknowledged": True, "index": index_name, "status": "already_exists"}
        else:
            print(f"âŒ Index '{index_name}' has invalid mapping, consider recreating")
            return None
    
    index_settings = {
        "settings": {
            "index": {
                "knn": True,
                "knn.algo_param.ef_search": 100,
                "number_of_shards": 3,
                "number_of_replicas": 2,
                "analysis": {
                    "analyzer": {
                        "nori_analyzer": {
                            "tokenizer": "nori_tokenizer",
                            "filter": ["nori_stop", "lowercase"]
                        }
                    },
                    "filter": {
                        "nori_stop": {
                            "type": "nori_part_of_speech",
                            "stoptags": ["J", "JKS", "JKB", "JKO", "JKG", "JKC", "JKV", "JKQ", "JX", "JC"]
                        }
                    }
                }
            }
        },
        "mappings": {
            "properties": {
                "entity": {
                    "properties": {
                        "name": {
                            "type": "text",
                            "analyzer": "nori_analyzer"
                        },
                        "synonym": {
                            "type": "keyword",
                            "fields": {
                                "text": {
                                    "type": "text",
                                    "analyzer": "nori_analyzer"
                                }
                            }
                        },
                        "entity_type": {
                            "type": "keyword"
                        },
                        "summary": {
                            "type": "text",
                            "analyzer": "nori_analyzer"
                        },
                        "summary_vec": {
                            "type": "knn_vector",
                            "dimension": 1024,
                            "method": {
                                "name": "hnsw",
                                "space_type": "l2",
                                "engine": "faiss",
                                "parameters": {
                                    "ef_construction": 128,
                                    "m": 16
                                }
                            }
                        },
                        "neptune_id": {
                            "type": "keyword"
                        }
                    }
                }
            }
        }
    }
    
    try:
        response = opensearch_client.indices.create(
            index=index_name,
            body=index_settings
        )
        print(f"âœ… Entity index '{index_name}' created successfully")
        
        # ìƒì„±ëœ ë§¤í•‘ ê²€ì¦
        if validate_entity_mapping(opensearch_client, index_name):
            print(f"âœ… Entity index mapping validation passed")
        else:
            print(f"âš ï¸ Entity index mapping validation failed")
            
        return response
    except Exception as e:
        print(f"âŒ Error creating entity index '{index_name}': {e}")
        return None


def check_index_settings(opensearch_client, index_name):
    """ì¸ë±ìŠ¤ ì„¤ì • í™•ì¸"""
    try:
        if not check_index_exists(opensearch_client, index_name):
            print(f"âŒ Index '{index_name}' does not exist")
            return None
            
        settings = opensearch_client.indices.get_settings(index=index_name)
        mappings = opensearch_client.indices.get_mapping(index=index_name)
        
        print(f"=== {index_name} Index Settings ===")
        print("Settings:", json.dumps(settings, indent=2, ensure_ascii=False))
        print("\nMappings:", json.dumps(mappings, indent=2, ensure_ascii=False))
        
        return {"settings": settings, "mappings": mappings}
    except Exception as e:
        print(f"âŒ Error checking index '{index_name}': {e}")
        return None


def validate_entity_mapping(opensearch_client, index_name):
    """ì—”í‹°í‹° ì¸ë±ìŠ¤ ë§¤í•‘ ê²€ì¦"""
    try:
        mapping = opensearch_client.indices.get_mapping(index=index_name)
        properties = mapping.get(index_name, {}).get('mappings', {}).get('properties', {})
        entity_props = properties.get('entity', {}).get('properties', {})
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = {
            'name': 'text',
            'entity_type': 'keyword', 
            'summary': 'text',
            'summary_vec': 'knn_vector',
            'neptune_id': 'keyword'
        }
        
        for field, expected_type in required_fields.items():
            if field not in entity_props:
                print(f"âŒ Missing field: entity.{field}")
                return False
                
            actual_type = entity_props[field].get('type')
            if actual_type != expected_type:
                print(f"âŒ Wrong type for entity.{field}: expected {expected_type}, got {actual_type}")
                return False
        
        # ë²¡í„° í•„ë“œ ìƒì„¸ ê²€ì¦
        vec_field = entity_props.get('summary_vec', {})
        if vec_field.get('dimension') != 1024:
            print(f"âŒ Wrong vector dimension: expected 1024, got {vec_field.get('dimension')}")
            return False
            
        print(f"âœ… Entity mapping validation passed for '{index_name}'")
        return True
        
    except Exception as e:
        print(f"âŒ Error validating entity mapping for '{index_name}': {e}")
        return False


def validate_chunk_mapping(opensearch_client, index_name):
    """ì²­í¬ ì¸ë±ìŠ¤ ë§¤í•‘ ê²€ì¦"""
    try:
        mapping = opensearch_client.indices.get_mapping(index=index_name)
        properties = mapping.get(index_name, {}).get('mappings', {}).get('properties', {})
        chunk_props = properties.get('chunk', {}).get('properties', {})
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = {
            'chunk_id': 'text',
            'chunk_text': 'text',
            'source_id': 'keyword',
            'summary': 'text',
            'summary_vec': 'knn_vector',
            'neptune_id': 'keyword'
        }
        
        for field, expected_type in required_fields.items():
            if field not in chunk_props:
                print(f"âŒ Missing field: chunk.{field}")
                return False
                
            actual_type = chunk_props[field].get('type')
            if actual_type != expected_type:
                print(f"âŒ Wrong type for chunk.{field}: expected {expected_type}, got {actual_type}")
                return False
        
        # ë²¡í„° í•„ë“œ ìƒì„¸ ê²€ì¦
        vec_field = chunk_props.get('summary_vec', {})
        if vec_field.get('dimension') != 1024:
            print(f"âŒ Wrong vector dimension: expected 1024, got {vec_field.get('dimension')}")
            return False
            
        print(f"âœ… Chunk mapping validation passed for '{index_name}'")
        return True
        
    except Exception as e:
        print(f"âŒ Error validating chunk mapping for '{index_name}': {e}")
        return False


def recreate_entity_index(opensearch_client, index_name="movie_graph", backup_data=False):
    """
    ì—”í‹°í‹° ì¸ë±ìŠ¤ ì¬ìƒì„± (ê¸°ì¡´ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)
    
    Args:
        opensearch_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        backup_data: ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì—¬ë¶€ (í˜„ì¬ëŠ” ë¡œê·¸ë§Œ ì¶œë ¥)
    """
    print(f"ğŸ”„ '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì¤‘...")
    
    # ê¸°ì¡´ ë°ì´í„° ë°±ì—… (ì˜µì…˜)
    if backup_data and check_index_exists(opensearch_client, index_name):
        print(f"ğŸ“¦ '{index_name}' ë°ì´í„° ë°±ì—… ì¤‘... (êµ¬í˜„ í•„ìš”)")
        # TODO: ì‹¤ì œ ë°±ì—… ë¡œì§ êµ¬í˜„
    
    # 1. ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
    delete_result = delete_index(opensearch_client, index_name)
    if delete_result is None:
        print(f"âŒ '{index_name}' ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨")
        return None
    
    # 2. ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
    result = define_entity_index(opensearch_client, index_name)
    
    if result and result.get('acknowledged'):
        print(f"âœ… '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì™„ë£Œ!")
        
        # ë§¤í•‘ ê²€ì¦ ë° ì¶œë ¥
        if validate_entity_mapping(opensearch_client, index_name):
            mapping = opensearch_client.indices.get_mapping(index=index_name)
            summary_vec_mapping = mapping[index_name]['mappings']['properties']['entity']['properties']['summary_vec']
            print(f"ğŸ“‹ summary_vec í•„ë“œ íƒ€ì…: {summary_vec_mapping['type']}")
            print(f"ğŸ“ ë²¡í„° ì°¨ì›: {summary_vec_mapping['dimension']}")
            print(f"ğŸ”§ ë²¡í„° ì—”ì§„: {summary_vec_mapping['method']['engine']}")
        
        return result
    else:
        print(f"âŒ '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì‹¤íŒ¨!")
        return None


def recreate_chunk_index(opensearch_client, index_name="chunks_book", backup_data=False):
    """
    ì²­í¬ ì¸ë±ìŠ¤ ì¬ìƒì„± (ê¸°ì¡´ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)
    
    Args:
        opensearch_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        backup_data: ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì—¬ë¶€ (í˜„ì¬ëŠ” ë¡œê·¸ë§Œ ì¶œë ¥)
    """
    print(f"ğŸ”„ '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì¤‘...")
    
    # ê¸°ì¡´ ë°ì´í„° ë°±ì—… (ì˜µì…˜)
    if backup_data and check_index_exists(opensearch_client, index_name):
        print(f"ğŸ“¦ '{index_name}' ë°ì´í„° ë°±ì—… ì¤‘... (êµ¬í˜„ í•„ìš”)")
        # TODO: ì‹¤ì œ ë°±ì—… ë¡œì§ êµ¬í˜„
    
    # 1. ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
    delete_result = delete_index(opensearch_client, index_name)
    if delete_result is None:
        print(f"âŒ '{index_name}' ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨")
        return None
    
    # 2. ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
    result = define_chunk_index(opensearch_client, index_name)
    
    if result and result.get('acknowledged'):
        print(f"âœ… '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì™„ë£Œ!")
        
        # ë§¤í•‘ ê²€ì¦ ë° ì¶œë ¥
        if validate_chunk_mapping(opensearch_client, index_name):
            mapping = opensearch_client.indices.get_mapping(index=index_name)
            summary_vec_mapping = mapping[index_name]['mappings']['properties']['chunk']['properties']['summary_vec']
            print(f"ğŸ“‹ summary_vec í•„ë“œ íƒ€ì…: {summary_vec_mapping['type']}")
            print(f"ğŸ“ ë²¡í„° ì°¨ì›: {summary_vec_mapping['dimension']}")
            print(f"ğŸ”§ ë²¡í„° ì—”ì§„: {summary_vec_mapping['method']['engine']}")
        
        return result
    else:
        print(f"âŒ '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì‹¤íŒ¨!")
        return None


def create_or_validate_index(opensearch_client, index_name, index_type="entity"):
    """
    ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ê²€ì¦ (í†µí•© í•¨ìˆ˜)
    
    Args:
        opensearch_client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        index_type: ì¸ë±ìŠ¤ íƒ€ì… ("entity" ë˜ëŠ” "chunk")
    
    Returns:
        dict: ìƒì„±/ê²€ì¦ ê²°ê³¼
    """
    print(f"ğŸ” '{index_name}' ì¸ë±ìŠ¤ í™•ì¸ ì¤‘...")
    
    if index_type == "entity":
        create_func = define_entity_index
        validate_func = validate_entity_mapping
    elif index_type == "chunk":
        create_func = define_chunk_index
        validate_func = validate_chunk_mapping
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ íƒ€ì…: {index_type}")
        return None
    
    # ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
    if check_index_exists(opensearch_client, index_name):
        print(f"ğŸ“‹ '{index_name}' ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
        
        # ë§¤í•‘ ê²€ì¦
        if validate_func(opensearch_client, index_name):
            print(f"âœ… '{index_name}' ì¸ë±ìŠ¤ ë§¤í•‘ì´ ìœ íš¨í•©ë‹ˆë‹¤")
            return {"status": "valid", "action": "none", "index": index_name}
        else:
            print(f"âš ï¸ '{index_name}' ì¸ë±ìŠ¤ ë§¤í•‘ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return {"status": "invalid_mapping", "action": "recreate_needed", "index": index_name}
    else:
        print(f"ğŸ†• '{index_name}' ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤")
        result = create_func(opensearch_client, index_name)
        
        if result and result.get('acknowledged'):
            return {"status": "created", "action": "created", "index": index_name, "result": result}
        else:
            return {"status": "creation_failed", "action": "failed", "index": index_name}


if __name__ == "__main__":
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    from opensearch.opensearch_con import get_opensearch_client
    
    client = get_opensearch_client()
    
    print("ï¿½ OpvenSearch ì¸ë±ìŠ¤ ê´€ë¦¬ ë„êµ¬")
    print("=" * 50)
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (ê¸°ë³¸ê°’: movie_graph ì¬ìƒì„±)
    if len(sys.argv) > 1:
        action = sys.argv[1]
        index_name = sys.argv[2] if len(sys.argv) > 2 else "movie_graph"
    else:
        action = "recreate"
        index_name = "movie_graph"
    
    print(f"ğŸ“‹ Action: {action}")
    print(f"ğŸ“‹ Index: {index_name}")
    print("-" * 50)
    
    if action == "recreate":
        # ì¸ë±ìŠ¤ ì¬ìƒì„±
        result = recreate_entity_index(client, index_name)
        
        if result:
            print(f"\nğŸ‰ '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì„±ê³µ!")
        else:
            print(f"\nğŸ’¥ '{index_name}' ì¸ë±ìŠ¤ ì¬ìƒì„± ì‹¤íŒ¨!")
            
    elif action == "create":
        # ì¸ë±ìŠ¤ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œë§Œ)
        result = create_or_validate_index(client, index_name, "entity")
        print(f"\nğŸ“Š ê²°ê³¼: {result}")
        
    elif action == "validate":
        # ì¸ë±ìŠ¤ ê²€ì¦ë§Œ
        if check_index_exists(client, index_name):
            if validate_entity_mapping(client, index_name):
                print(f"\nâœ… '{index_name}' ì¸ë±ìŠ¤ ë§¤í•‘ì´ ìœ íš¨í•©ë‹ˆë‹¤!")
            else:
                print(f"\nâŒ '{index_name}' ì¸ë±ìŠ¤ ë§¤í•‘ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        else:
            print(f"\nâŒ '{index_name}' ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            
    elif action == "check":
        # ì¸ë±ìŠ¤ ì„¤ì • í™•ì¸
        result = check_index_settings(client, index_name)
        if result:
            print(f"\nğŸ“Š '{index_name}' ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ ì™„ë£Œ!")
        else:
            print(f"\nâŒ '{index_name}' ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨!")
            
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•¡ì…˜: {action}")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ì•¡ì…˜: recreate, create, validate, check")
        print("ì‚¬ìš©ë²•: python opensearch_index_setting.py [action] [index_name]")
        print("ì˜ˆì‹œ: python opensearch_index_setting.py recreate entities_book")