"""
Neptune __Chunk__ ë…¸ë“œë¥¼ ì½ì–´ Bedrock ì„ë² ë”© ìƒì„± í›„ OpenSearch chunks ì¸ë±ìŠ¤ì— ì €ì¥
- Neptuneì—ì„œ __Chunk__ ë…¸ë“œ ì „ì²´ ì¡°íšŒ
- ê° chunkì˜ textë¥¼ Bedrock Titanìœ¼ë¡œ ì„ë² ë”©
- OpenSearch chunks ì¸ë±ìŠ¤ì— ì €ì¥ (context, context_vec, neptune_id)
- ë³‘ë ¬ ì²˜ë¦¬ (ThreadPoolExecutor)
"""
import os
import sys
import json
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from neptune.neptune_con import execute_cypher
from opensearch.opensearch_con import get_opensearch_client
from utils.bedrock_embedding import BedrockEmbedding

MAX_WORKERS = 10
BATCH_SIZE = 200  # Neptune ì¿¼ë¦¬ í˜ì´ì§•

stats_lock = threading.Lock()
print_lock = threading.Lock()
stats = {'success': 0, 'error': 0}


def fetch_all_chunks() -> list:
    """Neptuneì—ì„œ ëª¨ë“  __Chunk__ ë…¸ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    print("ğŸ“¦ Neptuneì—ì„œ __Chunk__ ë…¸ë“œ ì¡°íšŒ ì¤‘...")

    # ì „ì²´ ê°œìˆ˜ í™•ì¸
    count_result = execute_cypher("MATCH (c:__Chunk__) RETURN count(c) as cnt")
    total = 0
    if count_result and 'results' in count_result:
        total = count_result['results'][0].get('cnt', 0)
    print(f"   ì´ __Chunk__ ë…¸ë“œ: {total}ê°œ")

    # ì „ì²´ ì¡°íšŒ (id, text, neptune_id)
    query = """
    MATCH (c:__Chunk__)
    RETURN c.id AS id, c.text AS text, id(c) AS neptune_id
    """
    result = execute_cypher(query)
    if not result or 'results' not in result:
        print("âŒ __Chunk__ ì¡°íšŒ ì‹¤íŒ¨")
        return []

    chunks = result['results']
    print(f"   ì¡°íšŒ ì™„ë£Œ: {len(chunks)}ê°œ")
    return chunks


def process_chunk(idx, total, chunk, opensearch_client, embedder):
    """ë‹¨ì¼ chunk ì²˜ë¦¬: ì„ë² ë”© ìƒì„± + OpenSearch ì¸ë±ì‹±"""
    try:
        chunk_id = chunk.get('id', '')
        text = chunk.get('text', '')

        if not text:
            with print_lock:
                print(f"âš ï¸ [{idx}/{total}] {chunk_id} | text ì—†ìŒ, ìŠ¤í‚µ")
            return

        # Bedrock ì„ë² ë”© ìƒì„±
        context_vec = embedder.embed_text(text)

        # OpenSearchì— ì €ì¥
        # neptune_id = c.id (chunkì˜ id ì†ì„±) â†’ movie_search_chunk.pyì—ì„œ ì´ ê°’ìœ¼ë¡œ Neptune ë§¤ì¹­
        doc = {
            "chunk": {
                "context": text,
                "context_vec": context_vec,
                "neptune_id": chunk_id
            }
        }

        doc_id = chunk_id
        opensearch_client.index(index="chunks", id=doc_id, body=doc)

        with stats_lock:
            stats['success'] += 1
            cnt = stats['success']

        if cnt % 50 == 0 or cnt == total:
            with print_lock:
                print(f"âœ… [{cnt}/{total}] ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        with stats_lock:
            stats['error'] += 1
        with print_lock:
            print(f"âŒ [{idx}/{total}] {chunk.get('id', '?')} | ì—ëŸ¬: {e}")


def run():
    print("=" * 60)
    print("ğŸš€ Neptune __Chunk__ â†’ OpenSearch chunks ì„í¬íŠ¸")
    print(f"   Workers: {MAX_WORKERS}")
    print("=" * 60)

    # 1. Neptuneì—ì„œ __Chunk__ ì¡°íšŒ
    chunks = fetch_all_chunks()
    if not chunks:
        print("âš ï¸ ì²˜ë¦¬í•  chunkê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    total = len(chunks)

    # 2. OpenSearch í´ë¼ì´ì–¸íŠ¸ + ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸
    opensearch_client = get_opensearch_client()
    embedder = BedrockEmbedding()

    # 3. ê¸°ì¡´ chunks ì¸ë±ìŠ¤ ë¬¸ì„œ ìˆ˜ í™•ì¸
    try:
        count_resp = opensearch_client.count(index="chunks")
        existing = count_resp.get('count', 0)
        print(f"ğŸ“Š OpenSearch chunks ê¸°ì¡´ ë¬¸ì„œ: {existing}ê°œ")
    except:
        print("ğŸ“Š OpenSearch chunks ì¸ë±ìŠ¤ ì—†ìŒ ë˜ëŠ” ë¹„ì–´ìˆìŒ")

    # 4. ë³‘ë ¬ ì„ë² ë”© + ì¸ë±ì‹±
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ ì„ë² ë”© ìƒì„± + OpenSearch ì¸ë±ì‹± ({MAX_WORKERS} workers)")
    print("=" * 60)

    start_time = time.time()

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(process_chunk, i, total, chunk, opensearch_client, embedder): chunk
            for i, chunk in enumerate(chunks, 1)
        }
        for future in as_completed(futures):
            future.result()

    elapsed = time.time() - start_time

    # 5. ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨
    try:
        opensearch_client.indices.refresh(index="chunks")
    except Exception as e:
        print(f"âš ï¸ ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {e}")

    # 6. ìµœì¢… ê²°ê³¼
    try:
        final_count = opensearch_client.count(index="chunks").get('count', 0)
    except:
        final_count = '?'

    print(f"\n{'='*60}")
    print("ğŸ¯ ì™„ë£Œ!")
    print(f"   ì„±ê³µ: {stats['success']}ê°œ")
    print(f"   ì—ëŸ¬: {stats['error']}ê°œ")
    print(f"   ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
    print(f"   OpenSearch chunks ìµœì¢… ë¬¸ì„œ ìˆ˜: {final_count}")


if __name__ == "__main__":
    run()
